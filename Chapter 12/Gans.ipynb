{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '20 Samples from P & Q')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 20\n",
    "plt.figure(figsize=[10,5])\n",
    "plt.scatter(np.zeros(n), np.random.random(n), label='samples from $P$')\n",
    "plt.scatter(np.ones(n)*0.6, np.random.random(n), label=r'samples from $Q, \\theta = 0.6$')\n",
    "plt.xticks([-0.6, -0.3, 0.0, .3,.6, .9])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title(\"20 Samples from P & Q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_dim):\n",
    "    z = layers.Input(shape=noise_dim)\n",
    "    x = layers.Dense(units=4*4*1024)(z)\n",
    "    x = layers.Reshape((4,4,1024))(x)\n",
    "    x = layers.Conv2DTranspose(filters=512, kernel_size=5, strides=2, padding='same')(x)\n",
    "    x = layers.Conv2DTranspose(filters=256, kernel_size=5, strides=2, padding='same')(x)\n",
    "    x = layers.Conv2DTranspose(filters=128, kernel_size=5, strides=2, padding='same')(x)\n",
    "    x = layers.Conv2DTranspose(filters=num_channels, kernel_size=5, strides=2, padding='same')(x)\n",
    "    return Model(inputs = z, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_dim):\n",
    "    z = layers.Input(shape=noise_dim)\n",
    "    x = layers.Dense(units=7*7*256)(z)\n",
    "    x = layers.Reshape((7,7,256))(x)\n",
    "    for filter_size in [256,128, 64, num_channels]:\n",
    "        x = layers.Conv2DTranspose(filters=filter_size, kernel_size=5, strides=2, padding='same')(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    return Model(inputs = z, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_dim):\n",
    "    z = layers.Input(shape=noise_dim)\n",
    "    x = layers.Dense(units=4*4*1024)(z)\n",
    "    x = layers.Reshape((4,4,1024))(x)\n",
    "    for filter_size in [512,256,128,3]:\n",
    "        x = layers.Conv2DTranspose(filters=filter_size,\n",
    "               kernel_size=5, strides=2, padding='same')(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    return Model(inputs = z, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16384)             1654784   \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 8, 8, 512)         13107712  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 16, 16, 256)       3277056   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 32, 32, 128)       819328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 64, 64, 3)         9603      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 64, 64, 3)         12        \n",
      "=================================================================\n",
      "Total params: 18,872,079\n",
      "Trainable params: 18,870,281\n",
      "Non-trainable params: 1,798\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G = generator(100)\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    img = layers.Input(shape=[64,64,3])\n",
    "    x = layers.Conv2D(filters=128, kernel_size=5, strides=2,\n",
    "                      padding='same')(img)\n",
    "    for filter_size in [256, 512,1024]:\n",
    "        x = layers.Conv2D(filters=filter_size, kernel_size=5,\n",
    "                          strides=2, padding='same')(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    return Model(inputs = img, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "D =discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 128)       9728      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 1024)        13108224  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 16385     \n",
      "=================================================================\n",
      "Total params: 17,238,273\n",
      "Trainable params: 17,234,689\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"./celebfaces\"\n",
    "def load_real_samples():\n",
    "    \n",
    "    # Loading Dataset\n",
    "    data = np.load(os.path.join(input_path, 'img_celeba.npz'))\n",
    "    train_x = data['arr_0']\n",
    "    \n",
    "    train_x = train_x.astype('float32')\n",
    "    train_x = (train_x - 127.5) / 127.5\n",
    "    return train_x\n",
    "\n",
    "# Loading Dataset\n",
    "dataset = load_real_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 80, 80, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_resize(img):\n",
    "    return tf.image.resize_with_pad(img, 64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = tf.map_fn(fn=tf_resize, elems=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18a6f570b08>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(dataset1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50000, 64, 64, 3])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading Mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = tf.map_fn(fn=tf_resize, elems=train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 64, 64, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 64\n",
    "noise_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(noise_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 128)       819328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 56, 56, 64)        204864    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 112, 112, 1)       1601      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 112, 112, 1)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 112, 112, 1)       4         \n",
      "=================================================================\n",
      "Total params: 3,933,189\n",
      "Trainable params: 3,932,291\n",
      "Non-trainable params: 898\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(dataset1).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = G(noise, training=True)\n",
    "        \n",
    "        real_output = D(images, training=True)\n",
    "        fake_output = D(generated_images, training=True)\n",
    "\n",
    "        #gen_loss = generator_loss(fake_output)\n",
    "        gen_loss = generator_loss(real_output, fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        total_loss = gen_loss + disc_loss\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, G.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, D.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, G.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, D.trainable_variables))\n",
    "    total_loss_tracker.update_state(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef train(dataset, epochs):\\n    for epoch in range(epochs):\\n        start = time.time()\\n\\n    for image_batch in dataset:\\n        print('starting epoch')\\n        train_step(image_batch)\\n        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        print('starting epoch {}'.format(epoch))\n",
    "        \n",
    "        for image_batch in dataset:   \n",
    "            if image_batch.shape[0]==BATCH_SIZE:\n",
    "                train_step(image_batch)\n",
    "        print ('Time for epoch {} is {} sec, loss {}'.format(epoch + 1, time.time()-start, total_loss_tracker.result()))\n",
    "        \n",
    "'''\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "        print('starting epoch')\n",
    "        train_step(image_batch)\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 0\n",
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"input_5:0\", shape=(None, 64, 64, 3), dtype=float32) for input (None, 64, 64, 3), but it was re-called on a Tensor with incompatible shape (64, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    <ipython-input-39-a97da3e6ce10>:12 train_step  *\n        gen_loss = generator_loss(real_output, fake_output)\n    <ipython-input-33-6e8b2ad9bfcc>:2 generator_loss  *\n        features_fake = tf.reduce_mean(intermediate_D(fake_output))\n    C:\\Users\\tghosh\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\tghosh\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py:717 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    C:\\Users\\tghosh\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py:891 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    C:\\Users\\tghosh\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:737 __call__\n        self.name)\n    C:\\Users\\tghosh\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\input_spec.py:177 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer conv2d is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [64, 1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-422a2dcc2f99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-30302d02a4cc>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Time for epoch {} is {} sec, loss {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_loss_tracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    495\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    496\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 497\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2388\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2389\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2703\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2705\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2593\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    976\u001b[0m                                           converted_func)\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-39-a97da3e6ce10>:12 train_step  *\n        gen_loss = generator_loss(real_output, fake_output)\n    <ipython-input-33-6e8b2ad9bfcc>:2 generator_loss  *\n        features_fake = tf.reduce_mean(intermediate_D(fake_output))\n    C:\\Users\\tghosh\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\tghosh\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py:717 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    C:\\Users\\tghosh\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py:891 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    C:\\Users\\tghosh\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:737 __call__\n        self.name)\n    C:\\Users\\tghosh\\AppData\\Local\\Continuum\\anaconda3\\envs\\dl2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\input_spec.py:177 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer conv2d is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [64, 1]\n"
     ]
    }
   ],
   "source": [
    "train(train_dataset, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_D = Model(D.inputs, D.get_layer('conv2d_2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(real_output, fake_output):\n",
    "    features_fake = tf.reduce_mean(intermediate_D(fake_output))\n",
    "    features_real = tf.reduce_mean(intermediate_D(real_output))\n",
    "    \n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output) \\\n",
    "               + tf.square(tf.norm(features_fake-features_real))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minibatch discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5\n",
    "K = 2\n",
    "d = 3\n",
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = tf.random.uniform([D,d])\n",
    "M2 = tf.random.uniform([D,d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.90905535, 0.10405719, 0.09131753],\n",
       "       [0.02863705, 0.5825683 , 0.846153  ],\n",
       "       [0.8478004 , 0.39795244, 0.977985  ],\n",
       "       [0.48442566, 0.14110696, 0.4586779 ],\n",
       "       [0.9102944 , 0.35196173, 0.42107034]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.3017695 , 0.39971697, 0.23777246],\n",
       "       [0.7239461 , 0.1621412 , 0.9364575 ],\n",
       "       [0.12033594, 0.26026547, 0.09884906],\n",
       "       [0.51685464, 0.46610165, 0.24875021],\n",
       "       [0.67990506, 0.58456385, 0.65823436]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2, 3), dtype=float32, numpy=\n",
       "array([[[0.90905535, 0.10405719, 0.09131753],\n",
       "        [0.3017695 , 0.39971697, 0.23777246]],\n",
       "\n",
       "       [[0.02863705, 0.5825683 , 0.846153  ],\n",
       "        [0.7239461 , 0.1621412 , 0.9364575 ]],\n",
       "\n",
       "       [[0.8478004 , 0.39795244, 0.977985  ],\n",
       "        [0.12033594, 0.26026547, 0.09884906]],\n",
       "\n",
       "       [[0.48442566, 0.14110696, 0.4586779 ],\n",
       "        [0.51685464, 0.46610165, 0.24875021]],\n",
       "\n",
       "       [[0.9102944 , 0.35196173, 0.42107034],\n",
       "        [0.67990506, 0.58456385, 0.65823436]]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([tf.expand_dims(M1, axis=1), tf.expand_dims(M2, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2, 3), dtype=float32, numpy=\n",
       "array([[[0.46842444, 0.95186114, 0.31345356],\n",
       "        [0.13825059, 0.97335446, 0.23805988]],\n",
       "\n",
       "       [[0.94486415, 0.35316324, 0.04996717],\n",
       "        [0.68308115, 0.33421838, 0.523685  ]],\n",
       "\n",
       "       [[0.52339494, 0.6992692 , 0.32730103],\n",
       "        [0.9215299 , 0.7267034 , 0.9626744 ]],\n",
       "\n",
       "       [[0.8449619 , 0.03745961, 0.00374424],\n",
       "        [0.7552904 , 0.64674604, 0.8571209 ]],\n",
       "\n",
       "       [[0.06938469, 0.3339815 , 0.35222828],\n",
       "        [0.09033382, 0.82826924, 0.0475359 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = tf.random.uniform([D,K,d])\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
       "array([[0.53579485, 0.22043848, 0.8512554 , 0.59364235, 0.65108776],\n",
       "       [0.73988545, 0.39897418, 0.20312929, 0.01949179, 0.2785219 ],\n",
       "       [0.6069597 , 0.7328167 , 0.95966136, 0.9818381 , 0.60199976],\n",
       "       [0.08119547, 0.34293687, 0.32639813, 0.581118  , 0.4305358 ],\n",
       "       [0.09046173, 0.70486414, 0.20708644, 0.1790334 , 0.24359715],\n",
       "       [0.16241229, 0.89631736, 0.4913243 , 0.34857726, 0.08707452],\n",
       "       [0.194008  , 0.2368406 , 0.63229895, 0.5901879 , 0.7823255 ],\n",
       "       [0.54715204, 0.11998951, 0.7310027 , 0.34351993, 0.39887214],\n",
       "       [0.07517326, 0.9402046 , 0.7718631 , 0.7783884 , 0.77729225],\n",
       "       [0.21187091, 0.36405015, 0.9708501 , 0.21774459, 0.05188632]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx = tf.random.uniform([n,D])\n",
    "fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "multFeatures = tf.einsum('ij,jkl->ikl',fx, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2, 3), dtype=float32, numpy=\n",
       "array([[[1.1593724 , 0.89375454, 1.1838686 ],\n",
       "        [1.6287289 , 0.86550575, 0.95010316]],\n",
       "\n",
       "       [[0.81288606, 0.4292936 , 0.6704326 ],\n",
       "        [0.7319595 , 0.61242396, 0.33454993]],\n",
       "\n",
       "       [[1.5114806 , 1.1587211 , 1.8809394 ],\n",
       "        [2.3181956 , 1.4139124 , 1.0895185 ]],\n",
       "\n",
       "       [[0.67099416, 0.61236584, 0.8701151 ],\n",
       "        [1.1907641 , 0.6277503 , 0.5562905 ]],\n",
       "\n",
       "       [[0.5776517 , 0.29786566, 0.64153343],\n",
       "        [1.0281054 , 0.6158545 , 0.29951787]],\n",
       "\n",
       "       [[0.7304951 , 0.36885646, 0.99748605],\n",
       "        [1.3451461 , 0.8887679 , 0.38519326]],\n",
       "\n",
       "       [[0.97882664, 0.82929736, 0.96723014],\n",
       "        [1.5929219 , 0.70404845, 0.8988024 ]],\n",
       "\n",
       "       [[0.884442  , 0.61734825, 0.85950136],\n",
       "        [1.1161121 , 0.6410435 , 0.6862852 ]],\n",
       "\n",
       "       [[1.2765102 , 0.9387132 , 1.4809382 ],\n",
       "        [2.3712895 , 1.2054871 , 1.0078902 ]],\n",
       "\n",
       "       [[0.6213804 , 0.27805644, 0.7278147 ],\n",
       "        [1.1022834 , 0.61443794, 0.5242152 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 1, 2, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multFeaturesExpanded1 = tf.expand_dims(multFeatures,[1])\n",
    "multFeaturesExpanded1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = lambda x: x - multFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_wise_difference =  tf.abs(tf.map_fn(fn, multFeaturesExpanded1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10, 2, 3), dtype=float32, numpy=\n",
       "array([[[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[3.46486390e-01, 4.64460939e-01, 5.13436019e-01],\n",
       "         [8.96769345e-01, 2.53081799e-01, 6.15553260e-01]],\n",
       "\n",
       "        [[3.52108121e-01, 2.64966547e-01, 6.97070718e-01],\n",
       "         [6.89466715e-01, 5.48406661e-01, 1.39415383e-01]],\n",
       "\n",
       "        [[4.88378286e-01, 2.81388700e-01, 3.13753545e-01],\n",
       "         [4.37964797e-01, 2.37755477e-01, 3.93812656e-01]],\n",
       "\n",
       "        [[5.81720769e-01, 5.95888853e-01, 5.42335212e-01],\n",
       "         [6.00623488e-01, 2.49651253e-01, 6.50585294e-01]],\n",
       "\n",
       "        [[4.28877354e-01, 5.24898052e-01, 1.86382592e-01],\n",
       "         [2.83582807e-01, 2.32621431e-02, 5.64909935e-01]],\n",
       "\n",
       "        [[1.80545807e-01, 6.44571781e-02, 2.16638505e-01],\n",
       "         [3.58070135e-02, 1.61457300e-01, 5.13007641e-02]],\n",
       "\n",
       "        [[2.74930477e-01, 2.76406288e-01, 3.24367285e-01],\n",
       "         [5.12616754e-01, 2.24462271e-01, 2.63817966e-01]],\n",
       "\n",
       "        [[1.17137790e-01, 4.49586511e-02, 2.97069550e-01],\n",
       "         [7.42560625e-01, 3.39981377e-01, 5.77870607e-02]],\n",
       "\n",
       "        [[5.37992060e-01, 6.15698099e-01, 4.56053972e-01],\n",
       "         [5.26445508e-01, 2.51067817e-01, 4.25887942e-01]]],\n",
       "\n",
       "\n",
       "       [[[3.46486390e-01, 4.64460939e-01, 5.13436019e-01],\n",
       "         [8.96769345e-01, 2.53081799e-01, 6.15553260e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[6.98594511e-01, 7.29427457e-01, 1.21050668e+00],\n",
       "         [1.58623600e+00, 8.01488459e-01, 7.54968643e-01]],\n",
       "\n",
       "        [[1.41891897e-01, 1.83072239e-01, 1.99682474e-01],\n",
       "         [4.58804548e-01, 1.53263211e-02, 2.21740574e-01]],\n",
       "\n",
       "        [[2.35234380e-01, 1.31427944e-01, 2.88991928e-02],\n",
       "         [2.96145856e-01, 3.43054533e-03, 3.50320637e-02]],\n",
       "\n",
       "        [[8.23909640e-02, 6.04371428e-02, 3.27053428e-01],\n",
       "         [6.13186538e-01, 2.76343942e-01, 5.06433249e-02]],\n",
       "\n",
       "        [[1.65940583e-01, 4.00003761e-01, 2.96797514e-01],\n",
       "         [8.60962331e-01, 9.16244984e-02, 5.64252496e-01]],\n",
       "\n",
       "        [[7.15559125e-02, 1.88054651e-01, 1.89068735e-01],\n",
       "         [3.84152591e-01, 2.86195278e-02, 3.51735264e-01]],\n",
       "\n",
       "        [[4.63624179e-01, 5.09419560e-01, 8.10505569e-01],\n",
       "         [1.63932991e+00, 5.93063176e-01, 6.73340321e-01]],\n",
       "\n",
       "        [[1.91505671e-01, 1.51237160e-01, 5.73820472e-02],\n",
       "         [3.70323837e-01, 2.01398134e-03, 1.89665288e-01]]],\n",
       "\n",
       "\n",
       "       [[[3.52108121e-01, 2.64966547e-01, 6.97070718e-01],\n",
       "         [6.89466715e-01, 5.48406661e-01, 1.39415383e-01]],\n",
       "\n",
       "        [[6.98594511e-01, 7.29427457e-01, 1.21050668e+00],\n",
       "         [1.58623600e+00, 8.01488459e-01, 7.54968643e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[8.40486407e-01, 5.46355247e-01, 1.01082420e+00],\n",
       "         [1.12743151e+00, 7.86162138e-01, 5.33228040e-01]],\n",
       "\n",
       "        [[9.33828890e-01, 8.60855460e-01, 1.23940587e+00],\n",
       "         [1.29009020e+00, 7.98057914e-01, 7.90000677e-01]],\n",
       "\n",
       "        [[7.80985475e-01, 7.89864659e-01, 8.83453310e-01],\n",
       "         [9.73049521e-01, 5.25144517e-01, 7.04325318e-01]],\n",
       "\n",
       "        [[5.32653928e-01, 3.29423726e-01, 9.13709223e-01],\n",
       "         [7.25273728e-01, 7.09863961e-01, 1.90716147e-01]],\n",
       "\n",
       "        [[6.27038598e-01, 5.41372836e-01, 1.02143800e+00],\n",
       "         [1.20208347e+00, 7.72868931e-01, 4.03233349e-01]],\n",
       "\n",
       "        [[2.34970331e-01, 2.20007896e-01, 4.00001168e-01],\n",
       "         [5.30939102e-02, 2.08425283e-01, 8.16283226e-02]],\n",
       "\n",
       "        [[8.90100181e-01, 8.80664647e-01, 1.15312469e+00],\n",
       "         [1.21591222e+00, 7.99474478e-01, 5.65303326e-01]]],\n",
       "\n",
       "\n",
       "       [[[4.88378286e-01, 2.81388700e-01, 3.13753545e-01],\n",
       "         [4.37964797e-01, 2.37755477e-01, 3.93812656e-01]],\n",
       "\n",
       "        [[1.41891897e-01, 1.83072239e-01, 1.99682474e-01],\n",
       "         [4.58804548e-01, 1.53263211e-02, 2.21740574e-01]],\n",
       "\n",
       "        [[8.40486407e-01, 5.46355247e-01, 1.01082420e+00],\n",
       "         [1.12743151e+00, 7.86162138e-01, 5.33228040e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[9.33424830e-02, 3.14500183e-01, 2.28581667e-01],\n",
       "         [1.62658691e-01, 1.18957758e-02, 2.56772637e-01]],\n",
       "\n",
       "        [[5.95009327e-02, 2.43509382e-01, 1.27370954e-01],\n",
       "         [1.54381990e-01, 2.61017621e-01, 1.71097249e-01]],\n",
       "\n",
       "        [[3.07832479e-01, 2.16931522e-01, 9.71150398e-02],\n",
       "         [4.02157784e-01, 7.62981772e-02, 3.42511892e-01]],\n",
       "\n",
       "        [[2.13447809e-01, 4.98241186e-03, 1.06137395e-02],\n",
       "         [7.46519566e-02, 1.32932067e-02, 1.29994690e-01]],\n",
       "\n",
       "        [[6.05516076e-01, 3.26347351e-01, 6.10823095e-01],\n",
       "         [1.18052542e+00, 5.77736855e-01, 4.51599717e-01]],\n",
       "\n",
       "        [[4.96137738e-02, 3.34309399e-01, 1.42300427e-01],\n",
       "         [8.84807110e-02, 1.33123398e-02, 3.20752859e-02]]],\n",
       "\n",
       "\n",
       "       [[[5.81720769e-01, 5.95888853e-01, 5.42335212e-01],\n",
       "         [6.00623488e-01, 2.49651253e-01, 6.50585294e-01]],\n",
       "\n",
       "        [[2.35234380e-01, 1.31427944e-01, 2.88991928e-02],\n",
       "         [2.96145856e-01, 3.43054533e-03, 3.50320637e-02]],\n",
       "\n",
       "        [[9.33828890e-01, 8.60855460e-01, 1.23940587e+00],\n",
       "         [1.29009020e+00, 7.98057914e-01, 7.90000677e-01]],\n",
       "\n",
       "        [[9.33424830e-02, 3.14500183e-01, 2.28581667e-01],\n",
       "         [1.62658691e-01, 1.18957758e-02, 2.56772637e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.52843416e-01, 7.09908009e-02, 3.55952621e-01],\n",
       "         [3.17040682e-01, 2.72913396e-01, 8.56753886e-02]],\n",
       "\n",
       "        [[4.01174963e-01, 5.31431675e-01, 3.25696707e-01],\n",
       "         [5.64816475e-01, 8.81939530e-02, 5.99284530e-01]],\n",
       "\n",
       "        [[3.06790292e-01, 3.19482595e-01, 2.17967927e-01],\n",
       "         [8.80067348e-02, 2.51889825e-02, 3.86767328e-01]],\n",
       "\n",
       "        [[6.98858559e-01, 6.40847564e-01, 8.39404762e-01],\n",
       "         [1.34318411e+00, 5.89632630e-01, 7.08372355e-01]],\n",
       "\n",
       "        [[4.37287092e-02, 1.98092163e-02, 8.62812400e-02],\n",
       "         [7.41779804e-02, 1.41656399e-03, 2.24697351e-01]]],\n",
       "\n",
       "\n",
       "       [[[4.28877354e-01, 5.24898052e-01, 1.86382592e-01],\n",
       "         [2.83582807e-01, 2.32621431e-02, 5.64909935e-01]],\n",
       "\n",
       "        [[8.23909640e-02, 6.04371428e-02, 3.27053428e-01],\n",
       "         [6.13186538e-01, 2.76343942e-01, 5.06433249e-02]],\n",
       "\n",
       "        [[7.80985475e-01, 7.89864659e-01, 8.83453310e-01],\n",
       "         [9.73049521e-01, 5.25144517e-01, 7.04325318e-01]],\n",
       "\n",
       "        [[5.95009327e-02, 2.43509382e-01, 1.27370954e-01],\n",
       "         [1.54381990e-01, 2.61017621e-01, 1.71097249e-01]],\n",
       "\n",
       "        [[1.52843416e-01, 7.09908009e-02, 3.55952621e-01],\n",
       "         [3.17040682e-01, 2.72913396e-01, 8.56753886e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[2.48331547e-01, 4.60440904e-01, 3.02559137e-02],\n",
       "         [2.47775793e-01, 1.84719443e-01, 5.13609171e-01]],\n",
       "\n",
       "        [[1.53946877e-01, 2.48491794e-01, 1.37984693e-01],\n",
       "         [2.29033947e-01, 2.47724414e-01, 3.01091939e-01]],\n",
       "\n",
       "        [[5.46015143e-01, 5.69856763e-01, 4.83452141e-01],\n",
       "         [1.02614343e+00, 3.16719234e-01, 6.22696996e-01]],\n",
       "\n",
       "        [[1.09114707e-01, 9.08000171e-02, 2.69671381e-01],\n",
       "         [2.42862701e-01, 2.74329960e-01, 1.39021963e-01]]],\n",
       "\n",
       "\n",
       "       [[[1.80545807e-01, 6.44571781e-02, 2.16638505e-01],\n",
       "         [3.58070135e-02, 1.61457300e-01, 5.13007641e-02]],\n",
       "\n",
       "        [[1.65940583e-01, 4.00003761e-01, 2.96797514e-01],\n",
       "         [8.60962331e-01, 9.16244984e-02, 5.64252496e-01]],\n",
       "\n",
       "        [[5.32653928e-01, 3.29423726e-01, 9.13709223e-01],\n",
       "         [7.25273728e-01, 7.09863961e-01, 1.90716147e-01]],\n",
       "\n",
       "        [[3.07832479e-01, 2.16931522e-01, 9.71150398e-02],\n",
       "         [4.02157784e-01, 7.62981772e-02, 3.42511892e-01]],\n",
       "\n",
       "        [[4.01174963e-01, 5.31431675e-01, 3.25696707e-01],\n",
       "         [5.64816475e-01, 8.81939530e-02, 5.99284530e-01]],\n",
       "\n",
       "        [[2.48331547e-01, 4.60440904e-01, 3.02559137e-02],\n",
       "         [2.47775793e-01, 1.84719443e-01, 5.13609171e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[9.43846703e-02, 2.11949110e-01, 1.07728779e-01],\n",
       "         [4.76809740e-01, 6.30049706e-02, 2.12517202e-01]],\n",
       "\n",
       "        [[2.97683597e-01, 1.09415829e-01, 5.13708055e-01],\n",
       "         [7.78367639e-01, 5.01438677e-01, 1.09087825e-01]],\n",
       "\n",
       "        [[3.57446253e-01, 5.51240921e-01, 2.39415467e-01],\n",
       "         [4.90638494e-01, 8.96105170e-02, 3.74587178e-01]]],\n",
       "\n",
       "\n",
       "       [[[2.74930477e-01, 2.76406288e-01, 3.24367285e-01],\n",
       "         [5.12616754e-01, 2.24462271e-01, 2.63817966e-01]],\n",
       "\n",
       "        [[7.15559125e-02, 1.88054651e-01, 1.89068735e-01],\n",
       "         [3.84152591e-01, 2.86195278e-02, 3.51735264e-01]],\n",
       "\n",
       "        [[6.27038598e-01, 5.41372836e-01, 1.02143800e+00],\n",
       "         [1.20208347e+00, 7.72868931e-01, 4.03233349e-01]],\n",
       "\n",
       "        [[2.13447809e-01, 4.98241186e-03, 1.06137395e-02],\n",
       "         [7.46519566e-02, 1.32932067e-02, 1.29994690e-01]],\n",
       "\n",
       "        [[3.06790292e-01, 3.19482595e-01, 2.17967927e-01],\n",
       "         [8.80067348e-02, 2.51889825e-02, 3.86767328e-01]],\n",
       "\n",
       "        [[1.53946877e-01, 2.48491794e-01, 1.37984693e-01],\n",
       "         [2.29033947e-01, 2.47724414e-01, 3.01091939e-01]],\n",
       "\n",
       "        [[9.43846703e-02, 2.11949110e-01, 1.07728779e-01],\n",
       "         [4.76809740e-01, 6.30049706e-02, 2.12517202e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[3.92068267e-01, 3.21364939e-01, 6.21436834e-01],\n",
       "         [1.25517738e+00, 5.64443648e-01, 3.21605027e-01]],\n",
       "\n",
       "        [[2.63061583e-01, 3.39291811e-01, 1.31686687e-01],\n",
       "         [1.38287544e-02, 2.66055465e-02, 1.62069976e-01]]],\n",
       "\n",
       "\n",
       "       [[[1.17137790e-01, 4.49586511e-02, 2.97069550e-01],\n",
       "         [7.42560625e-01, 3.39981377e-01, 5.77870607e-02]],\n",
       "\n",
       "        [[4.63624179e-01, 5.09419560e-01, 8.10505569e-01],\n",
       "         [1.63932991e+00, 5.93063176e-01, 6.73340321e-01]],\n",
       "\n",
       "        [[2.34970331e-01, 2.20007896e-01, 4.00001168e-01],\n",
       "         [5.30939102e-02, 2.08425283e-01, 8.16283226e-02]],\n",
       "\n",
       "        [[6.05516076e-01, 3.26347351e-01, 6.10823095e-01],\n",
       "         [1.18052542e+00, 5.77736855e-01, 4.51599717e-01]],\n",
       "\n",
       "        [[6.98858559e-01, 6.40847564e-01, 8.39404762e-01],\n",
       "         [1.34318411e+00, 5.89632630e-01, 7.08372355e-01]],\n",
       "\n",
       "        [[5.46015143e-01, 5.69856763e-01, 4.83452141e-01],\n",
       "         [1.02614343e+00, 3.16719234e-01, 6.22696996e-01]],\n",
       "\n",
       "        [[2.97683597e-01, 1.09415829e-01, 5.13708055e-01],\n",
       "         [7.78367639e-01, 5.01438677e-01, 1.09087825e-01]],\n",
       "\n",
       "        [[3.92068267e-01, 3.21364939e-01, 6.21436834e-01],\n",
       "         [1.25517738e+00, 5.64443648e-01, 3.21605027e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[6.55129850e-01, 6.60656750e-01, 7.53123522e-01],\n",
       "         [1.26900613e+00, 5.91049194e-01, 4.83675003e-01]]],\n",
       "\n",
       "\n",
       "       [[[5.37992060e-01, 6.15698099e-01, 4.56053972e-01],\n",
       "         [5.26445508e-01, 2.51067817e-01, 4.25887942e-01]],\n",
       "\n",
       "        [[1.91505671e-01, 1.51237160e-01, 5.73820472e-02],\n",
       "         [3.70323837e-01, 2.01398134e-03, 1.89665288e-01]],\n",
       "\n",
       "        [[8.90100181e-01, 8.80664647e-01, 1.15312469e+00],\n",
       "         [1.21591222e+00, 7.99474478e-01, 5.65303326e-01]],\n",
       "\n",
       "        [[4.96137738e-02, 3.34309399e-01, 1.42300427e-01],\n",
       "         [8.84807110e-02, 1.33123398e-02, 3.20752859e-02]],\n",
       "\n",
       "        [[4.37287092e-02, 1.98092163e-02, 8.62812400e-02],\n",
       "         [7.41779804e-02, 1.41656399e-03, 2.24697351e-01]],\n",
       "\n",
       "        [[1.09114707e-01, 9.08000171e-02, 2.69671381e-01],\n",
       "         [2.42862701e-01, 2.74329960e-01, 1.39021963e-01]],\n",
       "\n",
       "        [[3.57446253e-01, 5.51240921e-01, 2.39415467e-01],\n",
       "         [4.90638494e-01, 8.96105170e-02, 3.74587178e-01]],\n",
       "\n",
       "        [[2.63061583e-01, 3.39291811e-01, 1.31686687e-01],\n",
       "         [1.38287544e-02, 2.66055465e-02, 1.62069976e-01]],\n",
       "\n",
       "        [[6.55129850e-01, 6.60656750e-01, 7.53123522e-01],\n",
       "         [1.26900613e+00, 5.91049194e-01, 4.83675003e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_wise_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_wise_difference = tf.abs(\n",
    "    tf.map_fn(lambda x: x - multFeatures,\n",
    "              tf.expand_dims(multFeatures,[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "multFeaturesDiff = tf.exp(\n",
    "            -tf.reduce_sum(\n",
    "                tf.abs(\n",
    "                    tf.map_fn(fn, multFeaturesExpanded1)\n",
    "                ),\n",
    "            axis=[3])\n",
    "        )\n",
    "output = tf.reduce_sum(multFeaturesDiff, axis=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[4.250483 , 4.1750574],\n",
       "       [5.1263275, 4.1288443],\n",
       "       [2.3254416, 2.623477 ],\n",
       "       [5.337405 , 5.3628964],\n",
       "       [4.67772  , 4.857558 ],\n",
       "       [5.12842  , 4.490942 ],\n",
       "       [4.896645 , 4.4156637],\n",
       "       [5.37877  , 5.201411 ],\n",
       "       [3.5418372, 2.8678563],\n",
       "       [4.9243836, 5.3776045]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
       "array([[0.05289634, 0.01884498, 0.02495264, 0.09018894],\n",
       "       [0.1362008 , 0.05144521, 0.11096726, 0.2175933 ],\n",
       "       [0.08272877, 0.04497003, 0.02741747, 0.0881411 ],\n",
       "       [0.8385502 , 0.41891354, 0.17943019, 0.7977139 ],\n",
       "       [0.32605034, 0.14356598, 0.2867352 , 0.9662033 ]], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tf.reduce_sum(multFeaturesDiff, axis=[1])\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss_wasserstein(real_output, fake_output):\n",
    "    return tf.reduce_mean(real_output) -tf.reduce_mean(fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss_wasserstein(real_output, fake_output):\n",
    "    return -tf.reduce_mean(fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight Clipping for the discriminator ( this must be added to train step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in D.trainable_variables:\n",
    "    p.assign( tf.clip_by_value(p, -0.01, +0.01)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(real_output, fake_output):\n",
    "    epsilon = tf.random.uniform([real_output.shape[0], 1, 1, 1], 0.0, 1.0)\n",
    "    x_hat = epsilon * real_output + (1 - epsilon) * fake_output\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x_hat)\n",
    "        d_hat = D(x_hat)\n",
    "    gradients = tape.gradient(d_hat, x_hat)\n",
    "    gradnorm_sqr_reg = tf.reduce_mean((tf.norm(gradients) - 1.0) ** 2)\n",
    "    return gradnorm_sqr_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.7859294>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re = tf.random.uniform([5, 64,64,3], 1.0, 2.0 )\n",
    "fk = tf.random.uniform([5, 64,64,3], 1.0, 2.0)\n",
    "gradient_penalty(re, fk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[1.0725139, 1.2218661],\n",
       "       [1.2067604, 1.664377 ]], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.6210046>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.norm(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.6210046>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sqrt(tf.reduce_sum(tf.square(m), axis=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 1, 1, 1), dtype=float32, numpy=\n",
       "array([[[[7.5757933e-01]]],\n",
       "\n",
       "\n",
       "       [[[9.7111738e-01]]],\n",
       "\n",
       "\n",
       "       [[[7.8766191e-01]]],\n",
       "\n",
       "\n",
       "       [[[2.7573109e-04]]],\n",
       "\n",
       "\n",
       "       [[[6.7579710e-01]]],\n",
       "\n",
       "\n",
       "       [[[9.9856865e-01]]],\n",
       "\n",
       "\n",
       "       [[[3.7026906e-01]]],\n",
       "\n",
       "\n",
       "       [[[4.6745968e-01]]],\n",
       "\n",
       "\n",
       "       [[[6.1199844e-01]]],\n",
       "\n",
       "\n",
       "       [[[4.6081674e-01]]],\n",
       "\n",
       "\n",
       "       [[[1.6070724e-01]]],\n",
       "\n",
       "\n",
       "       [[[4.9116135e-01]]],\n",
       "\n",
       "\n",
       "       [[[3.8885331e-01]]],\n",
       "\n",
       "\n",
       "       [[[6.4160383e-01]]],\n",
       "\n",
       "\n",
       "       [[[9.0654933e-01]]],\n",
       "\n",
       "\n",
       "       [[[7.4432731e-01]]],\n",
       "\n",
       "\n",
       "       [[[4.2748213e-02]]],\n",
       "\n",
       "\n",
       "       [[[7.7904367e-01]]],\n",
       "\n",
       "\n",
       "       [[[8.7087131e-01]]],\n",
       "\n",
       "\n",
       "       [[[7.9574490e-01]]],\n",
       "\n",
       "\n",
       "       [[[6.7831457e-01]]],\n",
       "\n",
       "\n",
       "       [[[5.6840730e-01]]],\n",
       "\n",
       "\n",
       "       [[[6.2250793e-01]]],\n",
       "\n",
       "\n",
       "       [[[7.7842081e-01]]],\n",
       "\n",
       "\n",
       "       [[[8.5946381e-01]]],\n",
       "\n",
       "\n",
       "       [[[1.7112136e-02]]],\n",
       "\n",
       "\n",
       "       [[[7.0106506e-02]]],\n",
       "\n",
       "\n",
       "       [[[9.9626327e-01]]],\n",
       "\n",
       "\n",
       "       [[[1.6848350e-01]]],\n",
       "\n",
       "\n",
       "       [[[2.8739107e-01]]],\n",
       "\n",
       "\n",
       "       [[[3.3128870e-01]]],\n",
       "\n",
       "\n",
       "       [[[2.9113281e-01]]]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = tf.random.uniform([32, 1, 1, 1], 0.0, 1.0)\n",
    "epsilon    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional GAN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CelebA comes with a list of 40 binary attributes. Theses attributes include gender. We can extract that as the class label and we have a binary class label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    img = layers.Input(shape=[64,64,3])\n",
    "    label = layers.Input(shape=[2,]) #for two classes\n",
    "    y = layers.Dense(64*64)(label)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    y = layers.Reshape((64,64,1))(y)\n",
    "    \n",
    "    x = layers.concatenate([img, y])\n",
    "    \n",
    "    x = layers.Conv2D(filters=128, kernel_size=5, strides=2, padding='same')(x)\n",
    "    for filter_size in [256, 512,1024]:\n",
    "        x = layers.Conv2D(filters=filter_size, kernel_size=5, strides=2, padding='same')(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    return Model(inputs = [img, label], outputs = x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "D= discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 4096)         12288       input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 64, 64, 1)    0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 4)    0           input_20[0][0]                   \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 128)  12928       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 256)  819456      conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 16, 16, 256)  0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 256)  1024        leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 512)    3277312     batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 8, 8, 512)    0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 512)    2048        leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 4, 4, 1024)   13108224    batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 4, 4, 1024)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 4, 1024)   4096        leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 16384)        0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            16385       flatten_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,253,761\n",
      "Trainable params: 17,250,177\n",
      "Non-trainable params: 3,584\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_dim):\n",
    "    z = layers.Input(shape=noise_dim)\n",
    "    x = layers.Dense(units=7*7*256)(z)\n",
    "    x = layers.Reshape((7,7,256))(x)\n",
    "    \n",
    "    label = layers.Input(shape=[2,]) #for two classes\n",
    "    y = layers.Dense(7*7)(label)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    y = layers.Reshape((7,7,1))(y)\n",
    "    \n",
    "    x = layers.concatenate([x, y])\n",
    "\n",
    "    for filter_size in [256,128, 64, num_channels]:\n",
    "        x = layers.Conv2DTranspose(filters=filter_size, kernel_size=5, strides=2, padding='same')(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    return Model(inputs = [z, label], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(noise_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 12544)        1266944     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 7, 7, 256)    0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 49)           147         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 7, 7, 256)    0           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 7, 7, 1)      0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 7, 7, 257)    0           leaky_re_lu_17[0][0]             \n",
      "                                                                 reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 14, 14, 256)  1645056     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 14, 14, 256)  0           conv2d_transpose_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 14, 14, 256)  1024        leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 28, 28, 128)  819328      batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 28, 28, 128)  0           conv2d_transpose_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 56, 56, 64)   204864      batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 56, 56, 64)   0           conv2d_transpose_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 56, 56, 64)   256         leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 112, 112, 1)  1601        batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 112, 112, 1)  0           conv2d_transpose_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 112, 112, 1)  4           leaky_re_lu_21[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 3,939,736\n",
      "Trainable params: 3,938,838\n",
      "Non-trainable params: 898\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = G(noise, training=True)\n",
    "        fake_labels = np.random.randint(0, 2, BATCH_SIZE)\n",
    "        \n",
    "        real_output = D([images,labels], training=True)\n",
    "        fake_output = D([generated_images,fake_labels], training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, G.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, D.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, G.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, D.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional GAN weith Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 4d473c1dd8becc155b73f8504c6f6626 so we will re-download the data.\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 19s 0us/step\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNet50(include_top=False,weights=\"imagenet\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([655, 521, 600, 560, 582, 544, 591, 694, 597, 652])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(500, 699, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
