{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solutions for mitigating GAN training issues: This notebook shows sample code for implementing feature matching and minibatch discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract activations from an intermediate layer of the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_dim):\n",
    "    z = layers.Input(shape=noise_dim)\n",
    "    x = layers.Dense(units=4*4*1024)(z)\n",
    "    x = layers.Reshape((4,4,1024))(x)\n",
    "    for filter_size in [512,256,128,3]:\n",
    "        x = layers.Conv2DTranspose(filters=filter_size,\n",
    "               kernel_size=5, strides=2, padding='same')(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    return Model(inputs = z, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    img = layers.Input(shape=[64,64,3])\n",
    "    x = layers.Conv2D(filters=128, kernel_size=5, strides=2,\n",
    "                      padding='same')(img)\n",
    "    for filter_size in [256, 512,1024]:\n",
    "        x = layers.Conv2D(filters=filter_size, kernel_size=5,\n",
    "                          strides=2, padding='same')(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    return Model(inputs = img, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(100)\n",
    "D =discriminator()\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_D = Model(D.inputs, D.get_layer('conv2d_2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(real_output, fake_output):\n",
    "    features_fake = tf.reduce_mean(intermediate_D(fake_output))\n",
    "    features_real = tf.reduce_mean(intermediate_D(real_output))\n",
    "    \n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output) \\\n",
    "               + tf.square(tf.norm(features_fake-features_real))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatch Discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itâ€™s based on the idea that a random sample from the real dataset will have diverse set of images, and hence, a minibatch of real images will be very diverse. So, if we somehow measure intra-minibatch similarity of images for a true random sample, we should get a very low similarity score. The samples from generator should also have these characteristics if the generator is a good one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 5 #feature dimension of an intermediate layer f(x)\n",
    "K = 2 #Number of lob-dimnsional projections\n",
    "d = 3 #Low dimnsion for projecting feature \n",
    "n = 10 #batch size of sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projection Matices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = tf.random.uniform([L,d])\n",
    "M2 = tf.random.uniform([L,d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K projection matrices togethers as a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = tf.concat([tf.expand_dims(M1, axis=1), tf.expand_dims(M2, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example random intermediate layer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = tf.random.uniform([n,L]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = tf.einsum('ij,jkl->ikl',fx, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_wise_L1 = tf.abs( \n",
    "  tf.map_fn(lambda x: tf.abs(x - projections) ,  tf.expand_dims(projections ,[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = tf.exp(-tf.reduce_sum(row_wise_L1, axis = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_score_out = tf.reduce_sum( sim_scores , axis=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_score_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
